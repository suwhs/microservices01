package main

import (
	"context"
	"fmt"
	"log"
	"os"
	"os/signal"
	"sync"
	"time"

	"github.com/kelseyhightower/envconfig"

	"whs.su/svcs/brokers"
	_ "whs.su/svcs/brokers/drivers/kafka"
	_ "whs.su/svcs/brokers/drivers/rabbitmq"
	_ "whs.su/svcs/brokers/drivers/redis"
)

type Config struct {
	RedisDB       string `envconfig:"REDIS_DB" required:"true"`
	RedisKey      string `envconfig:"REDIS_KEY" required:"true"`
	RabbitDB      string `envconfig:"RABBIT" required:"true"`
	RabbitKey     string `envconfig:"ID" required:"true"`
	RabbitResults string `envconfig:"RABBIT_RESULTS" required:"true"`
	KafkaAddr     string `envconfig:"KAFKA" required:"true"`
	KafkaQueue    string `envconfig:"KAFKA_TOPIC" required:"true"`
}

func main() {
	var cfg Config

	ctx, stop := signal.NotifyContext(context.Background(), os.Interrupt)
	defer stop()

	if err := envconfig.Process("", &cfg); err != nil {
		log.Fatalf("configuration error: %s", err.Error())
	}

	redis, err := brokers.NewBroker("redis", map[string]any{
		"host": cfg.RedisDB,
	})

	if err != nil {
		log.Fatalf("redis connection error: %s", err.Error())
	}

	rabbit, err := brokers.NewBroker("rabbitmq", map[string]any{"uri": cfg.RabbitDB})

	if err != nil {
		log.Fatalf("rabbitmq connection error: %s", err.Error())
	}

	kafka, err := brokers.NewBroker("kafka", map[string]any{"brokers": cfg.KafkaAddr})

	if err != nil {
		log.Fatalf("kafka connection error: %s", err.Error())
	}

	wg := sync.WaitGroup{}
	wg.Add(1)
	// read ids, generated by service1 from redis
	go brokers.ConsumeFunc(redis.NewConsumer(cfg.RedisKey), ctx, func(msg string) bool {
		return true
	}).Loop(func() { wg.Done() })

	wg.Add(1)
	// read { id: ..., value: ....}, publised by service2
	go brokers.ConsumeFunc(rabbit.NewConsumer(cfg.RabbitResults), ctx, func(msg string) bool {
		log.Printf("rabbits results: %s", msg)
		return true
	}).Loop(func() { wg.Done() })

	wg.Add(1)
	// write ids to rabbitmq for service1
	go brokers.ProduceLoop(rabbit.NewProducerWithContext(ctx, cfg.RabbitKey), func(ctx context.Context, msg chan string) {
		defer wg.Done()
		for counter := 0; counter < 100; counter++ {
		InnerLoop:
			for {
				select {
				case msg <- fmt.Sprintf("id%d", counter):
					break InnerLoop
				case <-time.After(500 * time.Millisecond):
					continue InnerLoop
				case <-ctx.Done():
					return
				}
			}
		}
	})

	wg.Add(1)
	// write values to kafka for service1
	go brokers.ProduceLoop(kafka.NewProducerWithContext(ctx, cfg.KafkaQueue), func(ctx context.Context, msg chan string) {
		defer wg.Done()
		for counter := 0; counter < 100; counter++ {
		InnerLoop:
			for {
				select {
				case msg <- fmt.Sprintf("%d", counter):
					break InnerLoop
				case <-time.After(500 * time.Millisecond):
					continue InnerLoop
				case <-ctx.Done():
					return
				}
			}
		}
	})
	log.Printf("wait for interrupt")
	<-ctx.Done()
	log.Printf("context cancelled")
	wg.Wait()
	log.Printf("tester shutdown")
}
